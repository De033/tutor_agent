import json
import os
from typing import Optional, Dict, Any, List
from enum import Enum
import re
import difflib
from pydantic import BaseModel, Field

from camel.agents import ChatAgent
from camel.messages import BaseMessage
from camel.models import OpenAICompatibleModel
from camel.toolkits import FunctionTool

from core.user_profile import UserProfile
from core.knowledge_base import KnowledgeBase
from core.planner import AnalyticalPlanner
from utils.parsers import parse_llm_json_output
from core.tools_custom import save_knowledge_base, add_concept_to_kb
from core.review_manager import ReviewManager, Flashcard

# --- ç»“æ„åŒ–è¾“å‡º ---
class Concept(BaseModel):
    definition: str = Field(..., description="The clear and concise definition of the concept.")
    example: str = Field(..., description="A simple and illustrative example of the concept.")
    socratic_prompts: List[str] = Field(..., min_length=2, description="A list of at least two Socratic questions to guide the user's thinking.")
    difficulty: int = Field(..., ge=1, le=5, description="The difficulty of the concept, rated from 1 (easiest) to 5 (hardest).")

class KnowledgeBaseModel(BaseModel):
    concepts: Dict[str, Concept] = Field(..., description="A dictionary where keys are the names of the sub-topics and values are their detailed concept structures.")

class ResponseStrategy(str, Enum):
    """Enumeration of possible high-level teaching strategies."""
    ANSWER_QUESTION = "answer_question"
    PROGRESS_TO_NEXT_CONCEPT = "progress_to_next_concept"
    REVIEW_AND_CLARIFY = "review_and_clarify"
    SOCRATIC_GUIDANCE = "socratic_guidance"
    CONSOLIDATE_AND_VERIFY = "consolidate_and_verify"
    HANDLE_IRRELEVANCE = "handle_irrelevance"
    FOLLOW_USER_LEAD = "follow_user_lead"
    ACKNOWLEDGE_AND_WAIT = "acknowledge_and_wait"

class Action(BaseModel):
    """A specific action to be executed by the Guidance Agent."""
    action_type: str = Field(..., description="The type of action, e.g., 'ask_question', 'explain'.")
    content: str = Field(..., description="The content for the action, e.g., the question text or explanation.")

class FullPedagogicalDecisionModel(BaseModel):
    """A comprehensive model for the pedagogical agent's decision."""
    analysis: str = Field(..., description="A brief, internal analysis of the user's input and current state. This is your scratchpad for thinking.")
    response_strategy: ResponseStrategy = Field(..., description="The chosen high-level strategy for this turn.")
    action: Action = Field(..., description="The specific action to be taken to implement the strategy.")

class FlashcardContent(BaseModel):
    """A Pydantic model to structure the output of the FlashcardGeneratorAgent."""
    question: str = Field(..., description="The 'front' of the flashcard, posing a single, clear question.")
    answer: str = Field(..., description="The 'back' of the flashcard, providing a concise and accurate answer.")

class FlashcardBatch(BaseModel):
    """A Pydantic model for receiving a batch of flashcards from the generator agent."""
    cards: List[FlashcardContent] = Field(..., description="A list of generated flashcard question-answer pairs.")

class CardableDetails(BaseModel):
    """A model to determine if there are card-worthy details in a conversation."""
    has_cardable_details: bool = Field(..., description="True if specific, atomic facts were mentioned that are suitable for a new flashcard.")



# --- æ¨¡å—4: æ™ºèƒ½å¯¼å¸ˆAgent (ç¼–æ’å™¨) ---
class TutorState(Enum):
    IDLE = 0
    ANALYZING_GOAL = 1
    GENERATING_KB = 2
    TUTORING = 3
    AWAITING_PLAN_CONFIRMATION = 4
 # çŠ¶æ€æœº 
class IntelligentTutorAgent:
    """
    ä¸€ä¸ªåŠ¨æ€çš„ã€å›´ç»•å¯¹è¯ç”Ÿæˆæ•™å­¦å†…å®¹çš„æ™ºèƒ½å¯¼å¸ˆã€‚
    å®ç°äº†ä»å®šä¹‰å­¦ä¹ ç›®æ ‡ã€åŠ¨æ€ç”ŸæˆçŸ¥è¯†åº“åˆ°ä¸ªæ€§åŒ–æ•™å­¦çš„å®Œæ•´æµç¨‹ã€‚
    """
    def __init__(self, user_profile: UserProfile,
                 model_config: Dict[str, Any]):
        self.user_profile = user_profile
        self.knowledge_base = KnowledgeBase()
        self.current_concept_id: Optional[str] = None
        self.analytical_planner = AnalyticalPlanner()
        self.review_manager = ReviewManager(user_profile)
        self.state = TutorState.IDLE
        self.learning_blueprint: Dict[str, Any] = {
            "status": "incomplete", "topic": None, "sub_topics": [], 
            "current_level": "unknown", "learning_style": "unknown"
        }
        self.uploaded_material: Optional[str] = None
        self.history: List[Dict[str, Any]] = []
        
        self.model_instance = OpenAICompatibleModel(
            model_type=model_config.get("model_type"),
            url=model_config.get("url"),
            model_config_dict={"temperature": model_config.get("temperature")},
            api_key=model_config.get("api_key"),
        )

        self.goal_analyzer_agent = self._create_goal_analyzer_agent()
        self.kb_creator_agent = self._create_kb_creator_agent()
        self.guidance_agent = self._create_guidance_agent()
        self.content_analyzer_agent = self._create_content_analyzer_agent()
        self.intent_classifier_agent = self._create_intent_classifier_agent()
        self.strategy_agent = self._create_pedagogical_strategy_agent()
        self.flashcard_decision_agent = self._create_flashcard_decision_agent()
        self.single_flashcard_agent = self._create_single_flashcard_agent()

    def _create_goal_analyzer_agent(self) -> ChatAgent:
        system_prompt = """ä½ æ˜¯ä¸€ä½é¡¶çº§çš„å­¦ä¹ é¡¾é—®ã€‚ä½ çš„ç›®æ ‡æ˜¯é€šè¿‡å¯¹è¯ï¼Œå¼•å¯¼ç”¨æˆ·æ˜ç¡®ä»–ä»¬çš„å­¦ä¹ éœ€æ±‚ï¼Œå¹¶ç”Ÿæˆä¸€ä¸ªç»“æ„åŒ–çš„JSON"å­¦ä¹ éœ€æ±‚æ¸…å•"ã€‚
ä¸¥æ ¼éµå¾ªä»¥ä¸‹å¯¹è¯æµç¨‹å’ŒJSONæ ¼å¼ï¼š
1.  **é—®å€™ä¸å¯åŠ¨**: å½“ç”¨æˆ·è¡¨è¾¾å­¦ä¹ æ„æ„¿æ—¶ï¼Œçƒ­æƒ…é—®å€™å¹¶å¼€å§‹æé—®ã€‚
2.  **æ¢å¯»ä¸»é¢˜ (topic)**: é¦–å…ˆè¯¢é—®ç”¨æˆ·æƒ³å­¦ä¹ çš„å¤§ä¸»é¢˜æ˜¯ä»€ä¹ˆã€‚
3.  **æ¢å¯»å­ä¸»é¢˜ (sub_topics)**: å¼•å¯¼ç”¨æˆ·åˆ—å‡ºå¸Œæœ›è¦†ç›–çš„å…·ä½“çŸ¥è¯†ç‚¹ã€‚
4.  **è¯„ä¼°æ°´å¹³ (current_level)**: è¯¢é—®ç”¨æˆ·çš„ç°æœ‰æ°´å¹³ï¼ˆåˆå­¦è€…ã€æœ‰ä¸€å®šåŸºç¡€ã€ä¸“å®¶ï¼‰ã€‚
5.  **ç¡®è®¤é£æ ¼ (learning_style)**: è¯¢é—®ç”¨æˆ·åå¥½çš„å­¦ä¹ é£æ ¼ï¼ˆä¾‹å¦‚ï¼šè‹æ ¼æ‹‰åº•å¼ã€å¤šä¸€äº›å®ä¾‹ã€å¿«é€Ÿç›´æ¥ï¼‰ã€‚
6.  **æ£€æŸ¥ç¡®è®¤**: åœ¨æ”¶é›†å®Œæ‰€æœ‰ä¿¡æ¯åï¼Œå‘ç”¨æˆ·æ±‡æ€»å¹¶è¯·æ±‚ç¡®è®¤ã€‚
7.  **æœ€ç»ˆè¾“å‡º**: ä¸€æ—¦ç”¨æˆ·ç¡®è®¤ï¼Œä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¾“å‡ºï¼Œä¸è¦æœ‰ä»»ä½•é¢å¤–æ–‡å­—ã€‚

{
  "status": "complete" | "incomplete",
  "topic": "string | null",
  "sub_topics": ["string 1", "string 2", ...] | [],
  "current_level": "beginner" | "intermediate" | "advanced" | "unknown",
  "learning_style": "socratic" | "example_driven" | "direct" | "unknown",
  "next_question": "string_next_question_to_ask_user"
}
"""
        return ChatAgent(
            BaseMessage.make_assistant_message("Learning Goal Analyzer", system_prompt),
            model=self.model_instance
        )

    def _create_intent_classifier_agent(self) -> ChatAgent:
        system_prompt = """You are a highly-focused intent classifier. Your task is to analyze a user's response to a proposed learning plan and classify their intent.

You have just presented the user with a learning plan and asked for their confirmation (e.g., "I've created this plan for you, what do you think?"). Now you need to understand their reply.

Strictly output a JSON object with a single key "intent" and one of the following three values:
- "confirm": The user agrees with the plan and wants to proceed. Examples: "yes", "ok", "good", "let's start", "å¼€å§‹å­¦ä¹ ", "å¥½çš„", "å¯ä»¥", "æ²¡é—®é¢˜", "å°±è¿™ä¹ˆåŠ".
- "reject": The user wants to change the plan or has expressed dissatisfaction. Examples: "no", "not good", "change", "ä¸å¯¹", "è°ƒæ•´ä¸€ä¸‹", "æˆ‘æƒ³æ”¹ä¸€ä¸‹".
- "unclear": The user's response is ambiguous, off-topic, or a question. Examples: "How long will this take?", "ä¸ºä»€ä¹ˆæ˜¯è¿™äº›ä¸»é¢˜ï¼Ÿ".

Example 1:
User says: "Looks great, let's do it!"
Your output: {"intent": "confirm"}

Example 2:
User says: "Hmm, can we add a section on recursion?"
Your output: {"intent": "reject"}

Example 3:
User says: "å¼€å§‹å­¦ä¹ å§"
Your output: {"intent": "confirm"}
"""
        return ChatAgent(
            BaseMessage.make_assistant_message("Intent Classifier", system_prompt),
            model=self.model_instance
        )

    def _create_content_analyzer_agent(self) -> ChatAgent:
        system_prompt = """ä½ æ˜¯ä¸€ä½é¡¶çº§çš„è¯¾ç¨‹è§„åˆ’å¸ˆå’Œå†…å®¹åˆ†æä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯åˆ†æç”¨æˆ·æä¾›çš„æ–‡æœ¬ææ–™ï¼Œå¹¶ä»ä¸­æç‚¼å‡ºä¸€ä¸ªç»“æ„åŒ–çš„"å­¦ä¹ è“å›¾"ã€‚

æ ¸å¿ƒä»»åŠ¡ï¼š
1.  **é€šè¯»å…¨æ–‡**ï¼šä»”ç»†é˜…è¯»ç”¨æˆ·ä¸Šä¼ çš„å…¨éƒ¨ææ–™ï¼Œç†è§£å…¶æ ¸å¿ƒä¸»é¢˜å’Œå†…å®¹ç»“æ„ã€‚
2.  **æç‚¼ä¸»é¢˜**ï¼šç¡®å®šè¿™ä»½ææ–™æœ€æ ¸å¿ƒçš„ä¸»é¢˜ (topic)ã€‚
3.  **åˆ’åˆ†ç« èŠ‚**ï¼šå°†ææ–™å†…å®¹é€»è¾‘åœ°åˆ’åˆ†ä¸ºå¤šä¸ªå­ä¸»é¢˜ (sub_topics)ï¼Œè¿™åº”è¯¥ç±»ä¼¼äºä¸€æœ¬ä¹¦çš„ç›®å½•ã€‚
4.  **è¯„ä¼°éš¾åº¦å’Œé£æ ¼**ï¼šæ ¹æ®å†…å®¹çš„æ·±åº¦å’Œè¡¨è¾¾æ–¹å¼ï¼Œè¯„ä¼°æ•´ä½“å†…å®¹çš„å­¦ä¹ éš¾åº¦ (current_level: 'beginner', 'intermediate', 'advanced') å’Œæœ€é€‚åˆçš„æ•™å­¦é£æ ¼ (learning_style: 'socratic', 'example_driven', 'direct')ã€‚
5.  **ç”Ÿæˆæ€»ç»“å’Œç¡®è®¤è¯·æ±‚**ï¼šåˆ›å»ºä¸€æ®µé¢å‘ç”¨æˆ·çš„æ–‡æœ¬ (user_facing_summary)ï¼Œç”¨å‹å¥½çš„è¯­æ°”æ€»ç»“ä½ è§„åˆ’çš„å­¦ä¹ è“å›¾ï¼Œå¹¶è¯·æ±‚ç”¨æˆ·ç¡®è®¤ã€‚ä¾‹å¦‚ï¼š"æˆ‘åˆ†æäº†æ‚¨ä¸Šä¼ çš„æ–‡ä»¶ï¼Œå®ƒä¼¼ä¹æ˜¯å…³äº'çº¿æ€§ä»£æ•°'çš„ã€‚æˆ‘ä¸ºæ‚¨è§„åˆ’äº†ä»¥ä¸‹å­¦ä¹ è·¯å¾„ï¼š[å­ä¸»é¢˜1, å­ä¸»é¢˜2, ...]ã€‚æ‚¨è§‰å¾—è¿™ä¸ªè®¡åˆ’å¦‚ä½•ï¼Ÿå¦‚æœæ²¡é—®é¢˜ï¼Œæˆ‘ä»¬å°±å¯ä»¥åŸºäºè¿™ä¸ªè®¡åˆ’ä¸ºæ‚¨åˆ›å»ºè¯¦ç»†çš„çŸ¥è¯†åº“äº†ã€‚"
6.  **ä¸¥æ ¼çš„JSONè¾“å‡º**ï¼šå°†ä½ çš„æ‰€æœ‰åˆ†æç»“æœä¸¥æ ¼å°è£…åœ¨ä¸€ä¸ªJSONå¯¹è±¡ä¸­ï¼Œæ ¼å¼å¦‚ä¸‹ï¼Œä¸è¦æœ‰ä»»ä½•é¢å¤–æ–‡å­—ã€‚

{
  "learning_blueprint": {
    "status": "pending_confirmation",
    "topic": "string",
    "sub_topics": ["string 1", "string 2", ...],
    "current_level": "beginner" | "intermediate" | "advanced",
    "learning_style": "socratic" | "example_driven" | "direct"
  },
  "user_facing_summary": "string"
}
"""
        return ChatAgent(
            BaseMessage.make_assistant_message("Content Analyzer", system_prompt),
            model=self.model_instance
        )

    def _create_pedagogical_strategy_agent(self) -> ChatAgent:
        system_prompt = """You are an expert pedagogical strategist for a one-on-one AI tutor. Your role is to be the 'brain' of the tutor, deciding the best next step based on a comprehensive analysis of the learning context.

You will receive a JSON object containing the full context: the user's latest message, the current learning concept, the user's mastery level of that concept, and the conversation history.

Your task is to THINK step-by-step and then produce a SINGLE, VALID JSON object conforming to the `FullPedagogicalDecisionModel`.

**Your Thought Process (for the 'analysis' field):**
1.  **Analyze User's Intent:** What is the user trying to do? Are they asking a question? Answering my last question? Giving a command? Making a generic comment? Confused?
2.  **Evaluate User's Knowledge:** If they answered a question, how correct is it? Does it reveal misconceptions?
3.  **Consider Learning State:** What is their mastery level? Is it time to move on? Do we need to review?
4.  **Select a Strategy:** Based on the above, choose the most appropriate `ResponseStrategy` value (e.g., "answer_question", "progress_to_next_concept").
5.  **Formulate an Action:** Define the concrete `Action` that the tutor should say to the user.

**Strategy Guide & Output Format:**

*   **`answer_question`**: Used for direct questions.
*   **`progress_to_next_concept`**: Used when mastery is high.
*   **`review_and_clarify`**: Used for incorrect answers.
*   **`socratic_guidance`**: Used for partially correct answers.
*   **`consolidate_and_verify`**: Used for correct answers.
*   **`follow_user_lead`**: Used for user commands.
*   **`handle_irrelevance`**: Used for off-topic chat.
*   **`acknowledge_and_wait`**: Used for simple acknowledgements.

**IMPORTANT: Your final output must be ONLY the JSON object. The structure must be PERFECT.**
- The `response_strategy` field must contain one of the exact lowercase string values from the strategy guide (e.g., `"consolidate_and_verify"`).
- The `action` field MUST be a dictionary with two keys: `action_type` (a string) and `content` (a string).

**EXAMPLE of a PERFECT output:**
```json
{
  "analysis": "The user correctly answered the question, showing good understanding. I should consolidate this knowledge with a follow-up question.",
  "response_strategy": "consolidate_and_verify",
  "action": {
    "action_type": "ask_question",
    "content": "That's exactly right! Can you explain why that is the case?"
  }
}
```
"""
        return ChatAgent(
            BaseMessage.make_assistant_message("PedagogicalStrategist", system_prompt),
            model=self.model_instance
        )

    def _create_kb_creator_agent(self) -> ChatAgent:
        system_prompt = """ä½ æ˜¯ä¸€ä½é¡¶çº§çš„æ•™å­¦è®¾è®¡å¸ˆã€‚ä½ çš„ä»»åŠ¡æ˜¯æ ¹æ®ç»™å®šçš„"å­¦ä¹ éœ€æ±‚æ¸…å•"å’Œå¯é€‰çš„ç”¨æˆ·ä¸Šä¼ ææ–™ï¼Œåˆ›å»ºä¸€ä¸ªç»“æ„åŒ–çš„JSONçŸ¥è¯†åº“ã€‚
æ ¸å¿ƒä»»åŠ¡:
1.  **åˆ†æéœ€æ±‚**: ç†è§£éœ€æ±‚æ¸…å•ä¸­çš„æ¯ä¸€ä¸ªå­—æ®µï¼Œå°¤å…¶æ˜¯ `sub_topics`ã€‚
2.  **èåˆææ–™**: å¦‚æœç”¨æˆ·æä¾›äº†è¡¥å……ææ–™ï¼Œä¼˜å…ˆåŸºäºè¿™äº›ææ–™æ¥æ„å»ºçŸ¥è¯†ç‚¹ã€‚
3.  **ä¸»åŠ¨æ‰©å±•**: å¦‚æœæ²¡æœ‰ææ–™æˆ–ææ–™ä¸å……åˆ†ï¼Œä½ éœ€è¦åˆ©ç”¨ä½ è‡ªå·±çš„çŸ¥è¯†æ¥åˆ›å»ºå†…å®¹ã€‚
4.  **ç»“æ„åŒ–è¾“å‡º**: ä¸º`sub_topics`åˆ—è¡¨ä¸­çš„æ¯ä¸€ä¸ªå­ä¸»é¢˜ï¼Œç”Ÿæˆä¸€ä¸ªè¯¦ç»†çš„æ¡ç›®ï¼ŒåŒ…å« "definition", "example", "socratic_prompts" (ä¸€ä¸ªè‡³å°‘åŒ…å«ä¸¤ä¸ªé—®é¢˜çš„å­—ç¬¦ä¸²åˆ—è¡¨), å’Œ "difficulty" (éš¾åº¦ç³»æ•°, 1-5çš„æ•´æ•°)ã€‚
5.  **æœ€ç»ˆè¾“å‡º**: ä½ çš„æœ€ç»ˆè¾“å‡ºå¿…é¡»æ˜¯ä¸€ä¸ªä¸¥æ ¼éµå¾ªæŒ‡å®šæ ¼å¼çš„JSONå¯¹è±¡ï¼Œä¸è¦æ·»åŠ ä»»ä½•é¢å¤–çš„æ–‡å­—ã€å™è¿°æˆ–è§£é‡Šã€‚
**è‡³å…³é‡è¦**: æ•´ä¸ªè¾“å‡ºå¿…é¡»æ˜¯ä¸€ä¸ªJSONå¯¹è±¡ï¼Œä¸”åªåŒ…å«ä¸€ä¸ªé¡¶çº§é”® "concepts"ï¼Œå…¶å€¼ä¸ºæ‰€æœ‰å­ä¸»é¢˜ç»„æˆçš„å­—å…¸ã€‚
"""
        # æ³¨æ„ï¼šè¯¥ä»£ç†çš„å”¯ä¸€ä»»åŠ¡æ˜¯ç”Ÿæˆæœ‰æ•ˆçš„ Pydantic å¯¹è±¡ã€‚
        return ChatAgent(
            BaseMessage.make_assistant_message("Instructional Designer", system_prompt),
            model=self.model_instance
        )
    
    def _create_guidance_agent(self) -> ChatAgent:
        system_prompt = """ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ã€å¯Œæœ‰åŒç†å¿ƒçš„é€šç”¨å­¦ä¹ åŠ©æ‰‹ã€‚
ä½ çš„æ ¸å¿ƒä»»åŠ¡æ˜¯**ä¸¥æ ¼æ‰§è¡Œ**æ¥è‡ªä½ çš„"æ•™å­¦ç­–ç•¥å¸ˆ"æä¾›çš„æ•™å­¦è®¡åˆ’ã€‚ä½ æ”¶åˆ°çš„æŒ‡ä»¤ä¼šéå¸¸æ˜ç¡®ï¼ŒåŒ…å«äº†å›åº”çš„è¯­æ°”ã€è¦æ‰§è¡Œçš„åŠ¨ä½œä»¥åŠå…·ä½“å†…å®¹ã€‚

**ä½ çš„å·¥ä½œæµç¨‹:**
1.  **æ¥æ”¶æŒ‡ä»¤**: ä½ ä¼šå¾—åˆ°ä¸€ä¸ªåŒ…å« `strategy_name`, `spoken_response_style`, `next_action_type`, `action_details` çš„JSONå¯¹è±¡ï¼Œä»¥åŠç”¨æˆ·çš„åŸå§‹å›å¤ã€‚
2.  **ç†è§£å¹¶æ‰§è¡Œ**:
    -   **é¦–è¦åŸåˆ™**: å¦‚æœæ”¶åˆ°çš„ç­–ç•¥æ˜¯ `FollowStudentLead`ï¼Œè¯·å¿½ç•¥`action_details`ä¸­çš„é€šç”¨æŒ‡ä»¤ï¼Œä¼˜å…ˆåˆ†æç”¨æˆ·çš„åŸå§‹å›å¤ï¼Œå¹¶å°½åŠ›æ»¡è¶³ä»–ä»¬çš„è¦æ±‚ã€‚
    -   **å·¥å…·ä½¿ç”¨**: å¦‚æœç”¨æˆ·çš„æ„å›¾æ˜¯å­¦ä¹ ä¸€ä¸ªå½“å‰çŸ¥è¯†åº“ä¸­ä¸å­˜åœ¨çš„æ–°æ¦‚å¿µ (ä¾‹å¦‚ "æˆ‘æƒ³å­¦ä¹ ä¸€ä¸‹Pythonçš„åˆ—è¡¨æ¨å¯¼å¼"), ä½  **å¿…é¡»** ä½¿ç”¨ `add_concept_to_kb` å·¥å…·ã€‚ä¸ºäº†è°ƒç”¨æ­¤å·¥å…·ï¼Œä½ é¦–å…ˆéœ€è¦è‡ªè¡Œç”Ÿæˆè¯¥æ¦‚å¿µçš„ `definition`, `example`, `socratic_prompts` å’Œ `difficulty`ã€‚ç„¶åï¼Œä½ å¿…é¡»ä»å¯¹è¯å†å²ä¸­æ¨æ–­å‡ºå½“å‰çš„ `topic` (ä¾‹å¦‚ "PythonåŸºç¡€")ï¼Œå¹¶å°†æ‰€æœ‰è¿™äº›å‚æ•°ä¸€å¹¶ä¼ å…¥å·¥å…·ã€‚
    -   **å¸¸è§„æ‰§è¡Œ**: å¯¹äºå…¶ä»–ç­–ç•¥ï¼Œé‡‡ç”¨ `spoken_response_style` æŒ‡å®šçš„è¯­æ°”ï¼Œå¹¶æ‰§è¡Œ `action_details` ä¸­æè¿°çš„å…·ä½“è¡ŒåŠ¨ã€‚
3.  **è‡ªç„¶å›åº”**: ä½ çš„æ‰€æœ‰å›å¤éƒ½åº”è‡ªç„¶ã€æµç•…ï¼Œåƒä¸€ä¸ªçœŸæ­£çš„å¯¼å¸ˆã€‚
"""
        # åˆ›å»ºå·¥å…·å®ä¾‹
        add_concept_tool = FunctionTool(add_concept_to_kb)

        return ChatAgent(
            BaseMessage.make_assistant_message("Guidance Agent", system_prompt),
            model=self.model_instance,
            tools=[add_concept_tool] 
        )

    def _create_flashcard_decision_agent(self) -> ChatAgent:
        system_prompt = """You are an assistant that checks if a conversation snippet is complete enough to be a flashcard.
The user and AI have just had an exchange. Your task is to determine if this exchange represents a clear, self-contained piece of information suitable for a Question-Answer flashcard.

- If the AI has just clearly answered a user's question or explained a concept, and the user's response is a simple acknowledgment, respond with 'YES'.
- If the discussion is ongoing, incomplete, a command, or trivial social chat, respond with 'NO'.

Only respond with the word 'YES' or 'NO'.

Example 1:
User: "What is a python dictionary?"
AI: "A dictionary in Python is a collection of key-value pairs. Each key is connected to a value, and you can use a key to look up its corresponding value."
Your output: YES

Example 2:
User: "Ok got it, so what about lists?"
AI: "Great question! A list is an ordered collection of items."
Your output: NO (The user has immediately changed topic, the previous exchange was just an ack)

Example 3:
User: "That's cool."
AI: "I'm glad you think so! Do you have any other questions?"
Your output: NO (Trivial social chat)
"""
        return ChatAgent(
            BaseMessage.make_assistant_message("FlashcardDecisionAgent", system_prompt),
            model=self.model_instance,
        )

    def _create_single_flashcard_agent(self) -> ChatAgent:
        system_prompt = """ä½ æ˜¯ä¸€ä½ç²¾é€š"æ¦‚å¿µ/æè¿°æ¡†æ¶ (CDF)"çš„å­¦ä¹ ä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯å°†æä¾›çš„å¯¹è¯è§£æ„æˆä¸€ç»„ç»“æ„åŒ–ã€é«˜è´¨é‡çš„é—ªå¡ã€‚

**ä½ çš„æ€ç»´æµç¨‹ï¼š**
1.  **è¯†åˆ«æ ¸å¿ƒ`æ¦‚å¿µ`**ï¼šç²¾ç¡®å®šä½æ­£åœ¨è®¨è®ºçš„ä¸»è¦åè¯æˆ–æ€æƒ³ã€‚
2.  **æå–`æè¿°ç¬¦`**ï¼šæ‰¾åˆ°ä¸"æ¦‚å¿µ"ç›¸å…³çš„æ‰€æœ‰å±æ€§ã€å®šä¹‰ã€åŠŸèƒ½æˆ–é—®é¢˜ã€‚
3.  **æ„å»ºè‡ªç„¶è¯­è¨€é—®é¢˜**ï¼šä¸ºæ¯ä¸€ä¸ª`æè¿°ç¬¦`ï¼Œæ„å»ºä¸€ä¸ª**è‡ªç„¶çš„ã€å£è¯­åŒ–çš„é—®é¢˜**ã€‚è¿™ä¸ªé—®é¢˜å¿…é¡»æ¸…æ™°åœ°åŒ…å«`æ¦‚å¿µ`å’Œ`æè¿°ç¬¦`çš„å…³é”®è¯ã€‚
4.  **æä¾›è¯¦å°½ç­”æ¡ˆ**ï¼š`answer` å¿…é¡»æ˜¯æ¸…æ™°ã€å…·æœ‰æè¿°æ€§ä¸”å†…å®¹å®Œæ•´çš„è§£é‡Šã€‚

**å…³é”®è§„åˆ™ï¼š**
*   **é—®é¢˜å¿…é¡»æ˜¯è‡ªç„¶çš„é—®å¥**ï¼Œè€Œä¸æ˜¯ç”Ÿç¡¬çš„ `::` æ‹¼æ¥æ ¼å¼ã€‚
*   ç­”æ¡ˆå¿…é¡»å…·æœ‰æè¿°æ€§å’Œè§£é‡Šæ€§ã€‚
*   ä½ çš„æœ€ç»ˆè¾“å‡ºå¿…é¡»æ˜¯ä¸€ä¸ªåªåŒ…å« "cards" åˆ—è¡¨çš„JSONå¯¹è±¡ï¼Œä¸å«ä»»ä½•å…¶ä»–æ–‡å­—ã€‚

---
**ç¤ºä¾‹ï¼š**

**å¯¹è¯å†…å®¹ï¼š**
AI: "Pythonä¸­çš„å­—å…¸æ˜¯ä¸€ç§æ— åºçš„ã€å¯å˜çš„é”®å€¼å¯¹é›†åˆã€‚æ‰€è°“'å¯å˜'ï¼Œå°±æ˜¯æŒ‡ä½ å¯ä»¥åœ¨åˆ›å»ºä¹‹åä¿®æ”¹å®ƒã€‚"

**ä½ çš„åˆ†æ (å†…éƒ¨æ¨¡æ‹Ÿ):**
*   æ ¸å¿ƒæ¦‚å¿µ: `Python å­—å…¸`
*   æè¿°ç¬¦ 1: `å®šä¹‰`
*   æè¿°ç¬¦ 2: `å¯å˜æ€§ (Mutability)`

**ä½ çš„JSONè¾“å‡º:**
```json
{
  "cards": [
    {
      "question": "Python å­—å…¸çš„`å®šä¹‰`æ˜¯ä»€ä¹ˆï¼Ÿ",
      "answer": "å®ƒæ˜¯ä¸€ç§å†…ç½®çš„Pythonæ•°æ®ç»“æ„ï¼Œç”¨äºå°†æ¡ç›®å­˜å‚¨ä¸ºé”®å€¼å¯¹çš„é›†åˆï¼Œå¹¶ä¸”æ˜¯æ— åºå’Œå¯å˜çš„ã€‚"
    },
    {
      "question": "æˆ‘ä»¬åº”è¯¥å¦‚ä½•ç†è§£ Python å­—å…¸çš„`å¯å˜æ€§(Mutability)`ï¼Ÿ",
      "answer": "æ‰€è°“'å¯å˜'ï¼Œæ˜¯æŒ‡å­—å…¸çš„å†…å®¹å¯ä»¥åœ¨åˆ›å»ºåè¢«ä¿®æ”¹ï¼Œä¾‹å¦‚é€šè¿‡æ·»åŠ ã€æ›´æ–°æˆ–åˆ é™¤é”®å€¼å¯¹ã€‚"
    }
  ]
}
```
---
"""
        return ChatAgent(
            BaseMessage.make_assistant_message("SingleFlashcardAgent", system_prompt),
            model=self.model_instance,
        )

    def set_uploaded_material(self, content: str) -> str:
        """
        Stores the content of an uploaded file and triggers the analysis process.
        This is the primary entry point when a user uploads a document.
        """
        self.uploaded_material = content
        # ç«‹å³åˆ†æå†…å®¹å¹¶è¿”å›æ‘˜è¦ä»¥ä¾›ç¡®è®¤
        # ç”¨æˆ·çš„ä¸‹ä¸€ä¸ªæ¶ˆæ¯å°†æ˜¯ç¡®è®¤/æ‹’ç»è®¡åˆ’
        return self._handle_goal_analysis(user_response="")

    def step(self, user_response: str) -> str:
        """
        The main entry point for the user's conversational turn.
        Orchestrates the agent's response based on its current state.
        """

        response = ""
        if self.state == TutorState.IDLE:
            # å­¦ä¹ è¿‡ç¨‹çš„å¼€å§‹ï¼Œç”¨æˆ·ä¸Šä¼ æ–‡ä»¶æˆ–ç›´æ¥å‘Šè¯‰æˆ‘ä»–æƒ³è¦å­¦ä¹ ä»€ä¹ˆ
            response = self._handle_goal_analysis(user_response)
        elif self.state == TutorState.ANALYZING_GOAL:
            # åœ¨å¯¹è¯ä¸­å®šä¹‰å­¦ä¹ ç›®æ ‡
            response = self._handle_goal_analysis(user_response)
        elif self.state == TutorState.AWAITING_PLAN_CONFIRMATION:
            # ç”¨æˆ·æ­£åœ¨å“åº”æå‡ºçš„å­¦ä¹ è®¡åˆ’
            response = self._handle_plan_confirmation(user_response)
        elif self.state == TutorState.TUTORING:
            # æ­£åœ¨è¿›è¡Œä¸€ä¸ªæ´»è·ƒçš„è¾…å¯¼ä¼šè¯
            response = self._handle_tutoring(user_response)
        
        return response

    def _handle_goal_analysis(self, user_response: str) -> str:
        # æ„å›¾æ£€æµ‹ï¼Œå¤„ç†ç›´æ¥è¯·æ±‚çŸ¥è¯†åº“åˆ—è¡¨
        list_kb_triggers = ["çŸ¥è¯†åº“", "ä½ èƒ½æ•™ä»€ä¹ˆ", "æœ‰å“ªäº›ä¸»é¢˜", "ä½ ä¼šä»€ä¹ˆ", "ä½ èƒ½åšä»€ä¹ˆ"]
        if any(trigger in user_response for trigger in list_kb_triggers):
            available_kbs = self.knowledge_base.get_available_kb_names()
            if available_kbs:
                response = f"æˆ‘ç›®å‰å¯ä»¥æ•™æˆä»¥ä¸‹ä¸»é¢˜ï¼š\n- **{', '.join(available_kbs)}**\n\næ‚¨æƒ³å­¦ä¹ å“ªä¸€ä¸ªï¼Ÿæˆ–è€…ï¼Œæ‚¨ä¹Ÿå¯ä»¥é€šè¿‡ä¸Šä¼ æ–‡ä»¶æˆ–å‘Šè¯‰æˆ‘ä¸€ä¸ªæ–°ä¸»é¢˜æ¥åˆ›å»ºå…¨æ–°çš„è¯¾ç¨‹ã€‚"
            else:
                response = "æˆ‘çš„çŸ¥è¯†åº“ç›®å‰æ˜¯ç©ºçš„ã€‚æ‚¨å¯ä»¥é€šè¿‡ä¸Šä¼ æ–‡ä»¶æˆ–ç›´æ¥å‘Šè¯‰æˆ‘æ‚¨æƒ³å­¦ä¹ çš„ä¸»é¢˜æ¥åˆ›å»ºä¸€ä¸ªæ–°çš„çŸ¥è¯†åº“ã€‚"
            self._add_to_history("assistant", response)
            return response

        # å¦‚æœä¸Šä¼ äº†ææ–™ï¼Œé¦–å…ˆä½¿ç”¨å†…å®¹åˆ†æå™¨æå‡ºå­¦ä¹ è®¡åˆ’
        if self.uploaded_material:
            print("[Orchestrator] Found uploaded material, analyzing content...")
            analyzer_response = self.content_analyzer_agent.step(self.uploaded_material)
            
            # å¤„ç†åæ¸…é™¤ææ–™ä»¥é¿å…é‡æ–°åˆ†æ
            self.uploaded_material = None 

            parsed_result = parse_llm_json_output(analyzer_response.msg.content)
            if not parsed_result or "learning_blueprint" not in parsed_result:
                return "æŠ±æ­‰ï¼Œåˆ†ææ‚¨æä¾›çš„ææ–™æ—¶é‡åˆ°äº†é—®é¢˜ã€‚æ‚¨èƒ½é‡æ–°ä¸Šä¼ æˆ–ç›´æ¥å‘Šè¯‰æˆ‘æ‚¨æƒ³å­¦ä»€ä¹ˆå—ï¼Ÿ"

            self.learning_blueprint = parsed_result["learning_blueprint"]
            user_summary = parsed_result.get("user_facing_summary", "æˆ‘åˆ†æäº†æ‚¨çš„æ–‡æ¡£ï¼Œæˆ‘ä»¬å¯ä»¥å¼€å§‹å­¦ä¹ å—ï¼Ÿ")
            
            self.state = TutorState.AWAITING_PLAN_CONFIRMATION
            return user_summary

        # æ²¡æœ‰ä¸Šä¼ ææ–™ï¼Œä½¿ç”¨ç›®æ ‡åˆ†æå™¨
        print("[Orchestrator] No uploaded material, using Goal Analyzer.")
        # æ›´æ–°å­¦ä¹ éœ€æ±‚æ¸…å•
        self.learning_blueprint["last_user_response"] = user_response
        
        # å°†å­¦ä¹ éœ€æ±‚æ¸…å•å’Œç”¨æˆ·å›å¤ä¼ é€’ç»™ç›®æ ‡åˆ†æå™¨
        prompt = f"""
        è¿™æ˜¯æˆ‘ä»¬å½“å‰çš„å­¦ä¹ éœ€æ±‚æ¸…å•ï¼Œå…¶ä¸­æœ‰äº›ä¿¡æ¯å¯èƒ½ç¼ºå¤±äº†:
        ```json
        {json.dumps(self.learning_blueprint, ensure_ascii=False, indent=2)}
        ```
        è¿™æ˜¯ç”¨æˆ·åˆšåˆšçš„å›å¤: "{user_response}"
        è¯·æ ¹æ®ç”¨æˆ·çš„å›å¤æ›´æ–°æ¸…å•ï¼Œç„¶åå†³å®šä¸‹ä¸€æ­¥æ˜¯ç»§ç»­æé—®è¿˜æ˜¯ç¡®è®¤å®Œæˆã€‚
        å¦‚æœæ‰€æœ‰å­—æ®µéƒ½å·²å¡«å……ï¼Œè¯·å°†statusè®¾ä¸º'complete'å¹¶æœ€ç»ˆç¡®è®¤ä¸€æ¬¡ã€‚å¦åˆ™ï¼Œè¯·æå‡ºä¸‹ä¸€ä¸ªé—®é¢˜ã€‚
        """
        analyzer_response = self.goal_analyzer_agent.step(BaseMessage.make_user_message("User", prompt))

        if not analyzer_response or not analyzer_response.msgs:
            response = "æŠ±æ­‰ï¼Œæˆ‘åœ¨åˆ†ææ‚¨çš„å­¦ä¹ ç›®æ ‡æ—¶é‡åˆ°äº†é—®é¢˜ï¼Œè¯·å†è¯´ä¸€éå¥½å—ï¼Ÿ"
            self._add_to_history("assistant", response)
            return response

        response_text = analyzer_response.msgs[0].content
        analysis_json = parse_llm_json_output(response_text)

        if not analysis_json:
            self._add_to_history("assistant", response_text)
            return response_text

        self.learning_blueprint.update(analysis_json)
        print(f"[Orchestrator] Learning blueprint updated: {self.learning_blueprint}")

        if self.learning_blueprint.get("status") == "complete":
            self.state = TutorState.GENERATING_KB
            return self._generate_kb_and_start()
        else:
            next_question = self.learning_blueprint.get("next_question", "æˆ‘åº”è¯¥é—®ä»€ä¹ˆå‘¢ï¼Ÿ")
            self._add_to_history("assistant", next_question)
            return next_question

    def _handle_plan_confirmation(self, user_response: str) -> str:
        """Handles user confirmation for the auto-generated learning plan using an LLM for intent classification."""
        prompt = f"""The user was just shown a learning plan I generated. Now they have replied with: "{user_response}". Please classify their intent based on your instructions."""
        
        classifier_response = self.intent_classifier_agent.step(BaseMessage.make_user_message("User", prompt))

        # å¦‚æœLLMå¤±è´¥ï¼Œå›é€€åˆ°å…³é”®è¯ï¼Œé”™è¯¯å¤„ç†æ–¹å¼
        if not classifier_response or not classifier_response.msgs:
            if any(keyword in user_response.lower() for keyword in ["no", "ä¸äº†", "æ”¹", "è°ƒæ•´"]):
                intent = "reject"
            elif any(keyword in user_response.lower() for keyword in ["yes", "ok", "å¥½", "å¯ä»¥", "æ²¡é—®é¢˜", "ç¡®è®¤", "great", "looks good", "å¼€å§‹", "å­¦ä¹ "]):
                intent = "confirm"
            else:
                intent = "unclear"
        else:
            intent_json = parse_llm_json_output(classifier_response.msgs[0].content)
            intent = intent_json.get("intent") if intent_json else "unclear"

        if intent == "confirm":
            print("[Orchestrator] User confirmed the learning plan.")
            self.learning_blueprint["status"] = "complete"
            self.state = TutorState.GENERATING_KB
            self._add_to_history("assistant", "å¤ªå¥½äº†ï¼æˆ‘å°†æ ¹æ®è¿™ä¸ªè®¡åˆ’ä¸ºæ‚¨åˆ›å»ºè¯¦ç»†çš„çŸ¥è¯†åº“ï¼Œè¯·ç¨å€™...")
            return self._generate_kb_and_start()

        elif intent == "reject":
            print("[Orchestrator] User rejected the learning plan.")
            self.state = TutorState.ANALYZING_GOAL
            self.learning_blueprint = { "status": "incomplete", "topic": None, "sub_topics": [], "current_level": "unknown", "learning_style": "unknown" }
            response = "å¥½çš„ï¼Œæˆ‘ä»¬æ¥è°ƒæ•´ä¸€ä¸‹è®¡åˆ’ã€‚è¯·å‘Šè¯‰æˆ‘æ‚¨å¸Œæœ›åšå‡ºå“ªäº›æ”¹å˜ï¼Œæˆ–è€…æˆ‘ä»¬å¯ä»¥ä»å¤´å¼€å§‹è®¨è®ºæ‚¨çš„å­¦ä¹ ç›®æ ‡ã€‚"
            self._add_to_history("assistant", response)
            return response
        else: # "unclear"
            print("[Orchestrator] User intent for plan confirmation is unclear.")
            response = "æŠ±æ­‰ï¼Œæˆ‘ä¸å¤ªç¡®å®šæ‚¨çš„æ„æ€ã€‚æˆ‘ä»¬æ˜¯æŒ‰è¿™ä¸ªè®¡åˆ’å¼€å§‹ï¼Œè¿˜æ˜¯æ‚¨æƒ³åšä¸€äº›è°ƒæ•´å‘¢ï¼Ÿ"
            self._add_to_history("assistant", response)
            return response

    def _generate_kb_and_start(self) -> str:
        print("[Orchestrator] Starting knowledge base generation...")
        
        topic_to_load = self.learning_blueprint.get("topic")
        if not topic_to_load:
            self.state = TutorState.ANALYZING_GOAL
            response = "é”™è¯¯ï¼šå­¦ä¹ éœ€æ±‚ä¸­æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„ä¸»é¢˜åç§°ï¼Œæˆ‘ä»¬é‡æ–°å¼€å§‹å§ã€‚"
            self._add_to_history("assistant", response)
            return response

        max_retries = 2
        for attempt in range(max_retries):
            print(f"[Orchestrator] KB generation attempt {attempt + 1}/{max_retries} for topic '{topic_to_load}'...")
            
            prompt = f"""
            è¯·æ ¹æ®è¿™ä»½æœ€ç»ˆçš„å­¦ä¹ éœ€æ±‚æ¸…å•ï¼Œä¸ºç”¨æˆ·ç”Ÿæˆä¸€ä»½ç»“æ„åŒ–çš„çŸ¥è¯†åº“ã€‚
            ä½ çš„è¾“å‡ºå¿…é¡»ä¸¥æ ¼éµå®ˆå®šä¹‰çš„Pydanticæ¨¡å‹æ ¼å¼ã€‚
            å­¦ä¹ éœ€æ±‚æ¸…å•:
            ```json
            {json.dumps(self.learning_blueprint, ensure_ascii=False, indent=2)}
            ```
            ç”¨æˆ·ä¸Šä¼ çš„è¡¥å……ææ–™ (å¦‚æœæœ‰çš„è¯ï¼Œè¯·ä¼˜å…ˆä½¿ç”¨è¿™ä»½ææ–™ä¸­çš„å†…å®¹):
            ---
            {self.uploaded_material or "æ— "}
            ---
            """
            # ä½¿ç”¨ç»“æ„åŒ–è¾“å‡ºå’ŒPydanticæ¨¡å‹
            creator_response_obj = self.kb_creator_agent.step(
                BaseMessage.make_user_message("User", prompt),
            )

            kb_model = None
            # ç»“æ„åŒ–è¾“å‡ºå¯¹è±¡åº”è¯¥åœ¨ç¬¬ä¸€ä¸ªæ¶ˆæ¯çš„`content`ä¸­
            if creator_response_obj and creator_response_obj.msgs:
                content = creator_response_obj.msgs[0].content
                if isinstance(content, KnowledgeBaseModel):
                    # ç†æƒ³æƒ…å†µï¼šç›´æ¥Pydanticå¯¹è±¡
                    kb_model = content
                    print("[Orchestrator] Received Pydantic object directly.")
                elif isinstance(content, str):
                    # å›é€€æƒ…å†µï¼šå­—ç¬¦ä¸²å“åº”
                    try:
                        # å°è¯•1ï¼šç›´æ¥è§£ææ•´ä¸ªå­—ç¬¦ä¸²
                        kb_model = KnowledgeBaseModel.model_validate_json(content)
                        print("[Orchestrator] Successfully parsed the full string response.")
                    except Exception:
                        # å°è¯•2ï¼šä»å­—ç¬¦ä¸²ä¸­æå–JSONå—å¹¶è§£æå®ƒ
                        print("[Orchestrator] Full string parsing failed. Attempting to extract JSON block...")
                        match = re.search(r'\{.*\}', content, re.DOTALL)
                        if match:
                            json_str = match.group(0)
                            try:
                                kb_model = KnowledgeBaseModel.model_validate_json(json_str)
                                print("[Orchestrator] Successfully extracted and parsed JSON block from string.")
                            except Exception as e:
                                print(f"[Orchestrator] Failed to parse extracted JSON block: {e}")
                                kb_model = None
                        else:
                            print("[Orchestrator] No JSON block found in string.")
                            kb_model = None
                    
            # --- éªŒè¯é˜¶æ®µ ---
            validation_passed = False
            if kb_model:
                # 2. è¯­ä¹‰éªŒè¯ï¼šæ£€æŸ¥æ˜¯å¦è¦†ç›–æ‰€æœ‰å­ä¸»é¢˜
                expected_topics = self.learning_blueprint.get("sub_topics", [])
                # å¤„ç†æ²¡æœ‰ç‰¹å®šå­ä¸»é¢˜çš„æƒ…å†µï¼Œä»»ä½•æ¦‚å¿µéƒ½å¯ä»¥
                if not expected_topics:
                    if kb_model.concepts:
                        validation_passed = True
                        print("[Orchestrator] Syntactic validation passed (no specific sub-topics to check).")
                else:
                    generated_topics = list(kb_model.concepts.keys())
                    missing_topics = [topic for topic in expected_topics if topic not in generated_topics]

                    if not missing_topics:
                        validation_passed = True
                        print("[Orchestrator] KB data validated successfully (Syntactic & Semantic).")
                    else:
                        print(f"[Orchestrator] Semantic validation failed. Missing concepts for: {missing_topics}")
            else:
                response_type = type(creator_response_obj.msgs[0].content) if creator_response_obj and creator_response_obj.msgs else "None"
                print(f"[Orchestrator] KB generation failed: Could not obtain a valid Pydantic object. Got type: {response_type}")


            # --- è¡ŒåŠ¨é˜¶æ®µ ---
            if validation_passed:
                # ç°åœ¨ï¼Œ`kb_model` æ˜¯ä¸€ä¸ª Pydantic å¯¹è±¡ï¼Œå¯ä»¥ç›´æ¥ä½¿ç”¨
                print(f"[Orchestrator] Generated KB for topic: '{topic_to_load}' with {len(kb_model.concepts)} concepts.")

                save_result = ""
                try:
                    # å°†Pydanticæ¨¡å‹ç›´æ¥ä¼ é€’ç»™å·¥å…·å‡½æ•°
                    save_result = save_knowledge_base(topic=topic_to_load, concepts=kb_model.concepts)
                    print(f"[Orchestrator] {save_result}")
                except Exception as e:
                    print(f"[Orchestrator] Error saving knowledge base: {e}")
                    # å¦‚æœä¿å­˜å¤±è´¥ï¼Œä¸åº”è¯¥ç»§ç»­
                    # å¯ä»¥ä½¿ç”¨é‡è¯•æœºåˆ¶
                    if attempt < max_retries - 1:
                        continue
                    else:
                        error_message = f"æŠ±æ­‰ï¼Œæˆ‘åœ¨ä¸ºæ‚¨å°†çŸ¥è¯†åº“ä¿å­˜åˆ°æ–‡ä»¶æ—¶é‡åˆ°äº†é—®é¢˜: {e}"
                        self._add_to_history("assistant", error_message)
                        self.state = TutorState.ANALYZING_GOAL
                        return error_message

                if "success" in save_result.lower():
                    # --- é‡æ–°åŠ è½½çŸ¥è¯†åº“å¹¶å¼€å§‹è¾…å¯¼ ---
                    # æå–è§„èŒƒçš„ä¸»é¢˜åç§°ä»¥ç¡®ä¿ä¸€è‡´æ€§
                    match = re.search(r"knowledge_bases[\\/]([^\\/]+\.json)", save_result)
                    if match:
                        actual_filename = match.group(1)
                        canonical_topic_name = actual_filename[:-5].replace('_', ' ').title()
                        
                        # æ˜¾å¼é‡æ–°æ‰«æå’ŒåŠ è½½çŸ¥è¯†åº“
                        print(f"[Orchestrator] Reloading knowledge base to include '{canonical_topic_name}'...")
                        self.knowledge_base.scan_for_kbs()
                        loaded, reason = self.knowledge_base.load_kb_by_topic(canonical_topic_name)

                        if loaded:
                            print(f"[Orchestrator] KB for '{canonical_topic_name}' saved and reloaded successfully.")
                            # ç°åœ¨åŠ è½½äº†ï¼Œå¯ä»¥ç›´æ¥å¼€å§‹ä¼šè¯
                            return self._start_tutoring_session_from_loaded_kb()
                        else:
                            # è¿™ç§æƒ…å†µä¸å¤ªå¯èƒ½ï¼Œä½†ä»¥é˜²ä¸‡ä¸€ï¼Œå¢åŠ é”™è¯¯å¤„ç†
                            print(f"[Orchestrator] Post-save validation/reload failed: {reason}")
                            error_message = f"æŠ±æ­‰ï¼Œè™½ç„¶çŸ¥è¯†åº“æ–‡ä»¶å·²åˆ›å»ºï¼Œä½†åœ¨åŠ è½½æ—¶å¤±è´¥äº†: {reason}ã€‚è¯·ç¨åé‡è¯•ã€‚"
                            self._add_to_history("assistant", error_message)
                            self.state = TutorState.ANALYZING_GOAL
                            return error_message
                    else:
                        print("[Orchestrator] Critical error: Could not parse filename from save result.")
                else:
                    print(f"[Orchestrator] Failed to save the generated KB: {save_result}")

            # å¦‚æœéªŒè¯å¤±è´¥ï¼Œå›é€€åˆ°é‡è¯•é€»è¾‘
            if attempt < max_retries - 1:
                print("[Orchestrator] Retrying KB generation...")
                continue
            else:
                error_message = "æŠ±æ­‰ï¼Œæˆ‘åœ¨ä¸ºæ‚¨åˆ›å»ºçŸ¥è¯†åº“æ—¶é‡åˆ°äº†é—®é¢˜ã€‚AIæœªèƒ½ç”Ÿæˆç¬¦åˆè¦æ±‚çš„ã€å†…å®¹å®Œæ•´çš„æ•°æ®ã€‚è®©æˆ‘ä»¬å›åˆ°è§„åˆ’é˜¶æ®µï¼Œé‡æ–°å®šä¹‰ä¸€ä¸‹å­¦ä¹ ç›®æ ‡ä¹Ÿè®¸ä¼šæœ‰å¸®åŠ©ã€‚"
                self._add_to_history("assistant", error_message)
                self.state = TutorState.ANALYZING_GOAL
                return error_message
        
        # å›é€€
        self.state = TutorState.ANALYZING_GOAL
        return "å‘ç”ŸæœªçŸ¥é”™è¯¯ï¼ŒçŸ¥è¯†åº“ç”Ÿæˆå¤±è´¥ï¼Œè¯·é‡è¯•ã€‚"

    def _start_tutoring_session(self, topic_to_load: str) -> str:
        """Loads a knowledge base from a topic name and prepares the first question."""
        
        self.knowledge_base.scan_for_kbs()
        
        loaded, reason = self.knowledge_base.load_kb_by_topic(topic_to_load)
        if loaded:
            return self._start_tutoring_session_from_loaded_kb()
        else:
            self.state = TutorState.IDLE
            response = f"æŠ±æ­‰ï¼ŒåŠ è½½çŸ¥è¯†åº“ '{topic_to_load}' æ—¶å¤±è´¥äº†: {reason}ã€‚è®©æˆ‘ä»¬é‡æ–°å¼€å§‹å§ã€‚"
            self._add_to_history("assistant", response)
            return response

    def _start_tutoring_session_from_loaded_kb(self) -> str:
        """
        Starts the tutoring session assuming the knowledge base is already loaded.
        Prepares the first question for the user.
        """
        if not self.knowledge_base.is_loaded:
            self.state = TutorState.IDLE
            response = "é”™è¯¯ï¼šå°è¯•åœ¨æ²¡æœ‰åŠ è½½çŸ¥è¯†åº“çš„æƒ…å†µä¸‹å¼€å§‹æ•™å­¦ã€‚è¯·å…ˆé€‰æ‹©ä¸€ä¸ªä¸»é¢˜ã€‚"
            self._add_to_history("assistant", response)
            return response

        concept_keys = self.knowledge_base.get_concept_keys()
        if not concept_keys:
            self.state = TutorState.IDLE
            loaded_topic_name = self.knowledge_base.current_kb_name or "Unknown Topic"
            response = f"æŠ±æ­‰ï¼Œè™½ç„¶çŸ¥è¯†åº“ '{loaded_topic_name}' å·²åŠ è½½ï¼Œä½†é‡Œé¢æ²¡æœ‰æ‰¾åˆ°ä»»ä½•å­¦ä¹ æ¦‚å¿µã€‚AIå¯èƒ½æœªèƒ½æˆåŠŸç”Ÿæˆå†…å®¹ï¼Œæˆ‘ä»¬å¯ä»¥é‡æ–°è§„åˆ’ä¸€ä¸‹å­¦ä¹ è®¡åˆ’å—ï¼Ÿ"
            self._add_to_history("assistant", response)
            return response

        self.state = TutorState.TUTORING
        loaded_topic_name = self.knowledge_base.current_kb_name
        print(f"[Orchestrator] State changed to TUTORING. Starting session for topic: {loaded_topic_name}")
        
        # æ‰¾åˆ°ç¬¬ä¸€ä¸ªæœªæŒæ¡çš„æ¦‚å¿µ
        next_action = self.analytical_planner.select_next_action(
            self.user_profile, self.knowledge_base, current_concept_id=None
        )
        
        if next_action["action"] == "finish":
            self.state = TutorState.IDLE
            response = f"æ­å–œä½ ï¼æ ¹æ®è®°å½•ï¼Œä½ å·²ç»æŒæ¡äº† **{loaded_topic_name}** çš„æ‰€æœ‰æ¦‚å¿µã€‚"
            self._add_to_history("assistant", response)
            return response

        self.current_concept_id = next_action["concept_id"]
        concept = self.knowledge_base.get_concept(self.current_concept_id)

        if not concept:
            self.state = TutorState.IDLE
            response = f"æŠ±æ­‰ï¼Œæ— æ³•åŠ è½½çŸ¥è¯†åº“ '{loaded_topic_name}' ä¸­çš„æ¦‚å¿µ '{self.current_concept_id}'ã€‚æ–‡ä»¶å¯èƒ½å·²æŸåï¼Œæˆ‘ä»¬å¯ä»¥é‡æ–°è§„åˆ’ä¸€ä¸‹å—ï¼Ÿ"
            self._add_to_history("assistant", response)
            return response
            
        initial_question = concept.get('socratic_prompts', [f"ä½ å¯¹'{self.current_concept_id}'æœ‰ä»€ä¹ˆäº†è§£å—ï¼Ÿ"])[0]
        response = f"å¥½çš„ï¼Œæˆ‘ä»¬å¼€å§‹å­¦ä¹  **{loaded_topic_name}**ã€‚è®©æˆ‘ä»¬ä»ç¬¬ä¸€ä¸ªæ¦‚å¿µ **{self.current_concept_id}** å¼€å§‹å§ã€‚\n\n{initial_question}"
        self._add_to_history("assistant", response)
        return response

    def _handle_tutoring(self, user_response: str) -> str:
        """
        The core tutoring loop. It now acts as an action dispatcher based on
        the decision from the pedagogical strategy agent.
        """
        self._add_to_history("user", user_response)

        # 1. æ£€æŸ¥æ˜¯å¦å¯ä»¥åˆ›å»ºå¤ä¹ å¡ç‰‡
        card_notification = ""  # ç”¨äºå­˜å‚¨åˆ¶å¡æç¤ºä¿¡æ¯
        if len(self.history) >= 2:
            cards_created_count = self._check_and_trigger_flashcard_creation(
                conversation_snippet=self.history[-2:]
            )
            if cards_created_count > 0:
                if cards_created_count == 1:
                    card_notification = "ğŸ’³ æˆ‘å·²ä¸ºä½ åˆ›å»ºäº†1å¼ å¤ä¹ å¡ç‰‡ã€‚\n\n"
                else:
                    card_notification = f"ğŸ’³ æˆ‘å·²å°†åˆšæ‰çš„çŸ¥è¯†ç‚¹åˆ†è§£ï¼Œä¸ºä½ åˆ›å»ºäº† **{cards_created_count}** å¼ æ›´æ˜“äºè®°å¿†çš„åŸå­åŒ–å¡ç‰‡ã€‚\n\n"
        
        # 2. ç»§ç»­æ­£å¸¸çš„æ•™å­¦æµç¨‹ï¼Œæ— è®ºæ˜¯å¦åˆ›å»ºå¤ä¹ å¡ç‰‡
        current_concept_info = self.knowledge_base.get_concept(self.current_concept_id)
        if not current_concept_info:
            self.state = TutorState.IDLE
            return "é”™è¯¯ï¼šæ‰¾ä¸åˆ°å½“å‰æ¦‚å¿µï¼Œæ•™å­¦æµç¨‹ä¸­æ–­ã€‚"

        # 3. æ„å»ºå®Œæ•´çš„ä¸Šä¸‹æ–‡ï¼Œç”¨äºæ•™å­¦ç­–ç•¥çš„å†³ç­–
        context_for_strategist = {
            "user_message": user_response,
            "current_concept": {
                "name": self.current_concept_id,
                "difficulty": current_concept_info.get("difficulty", 3),
                "definition": current_concept_info.get("definition", ""),
            },
            "user_mastery_level": self.user_profile.knowledge_mastery.get(self.current_concept_id, 0.0),
            "conversation_history": [
                {"role": msg["role"], "content": msg["message"].content} 
                for msg in self.history
            ],
        }

        # 4. è°ƒç”¨'å¤§è„‘'è·å–ç»“æ„åŒ–å†³ç­–
        try:
            strategy_response = self.strategy_agent.step(
                BaseMessage.make_user_message("user", json.dumps(context_for_strategist, ensure_ascii=False)),
            )
            self.strategy_agent.reset()

            decision = None
            if strategy_response and strategy_response.msgs:
                content = strategy_response.msgs[0].content
                if isinstance(content, FullPedagogicalDecisionModel):
                    decision = content
                elif isinstance(content, str):
                    # Robustness: Handle cases where the model returns a string anyway
                    parsed_json = parse_llm_json_output(content)
                    if parsed_json:
                        decision = FullPedagogicalDecisionModel.model_validate(parsed_json)
            
            if not decision:
                raise ValueError("Failed to get a valid decision from the strategy agent.")

        except Exception as e:
            print(f"[Orchestrator] Error getting pedagogical decision: {e}")
            # å…³é”®å¤±è´¥å›é€€
            response_text = "æˆ‘å¥½åƒæœ‰ç‚¹å›°æƒ‘ï¼Œæˆ‘ä»¬èƒ½æ¢ä¸ªæ–¹å¼ç»§ç»­å—ï¼Ÿ"
            self._add_to_history("assistant", response_text)
            return response_text

        # 5. æ‰§è¡Œå†³ç­–ï¼Œä½¿ç”¨è°ƒåº¦é€»è¾‘
        print(f"[Orchestrator] Strategy: {decision.response_strategy.value} | Action: {decision.action.action_type}")

        # é»˜è®¤åŠ¨ä½œï¼šåªæ˜¯è¯´ä»£ç†å†³å®šçš„å†…å®¹
        response_text = decision.action.content
        
        # è°ƒåº¦å™¨ï¼Œç”¨äºéœ€è¦çŠ¶æ€æ”¹å˜çš„ç­–ç•¥
        if decision.response_strategy == ResponseStrategy.FOLLOW_USER_LEAD:
            # Here you could add logic to parse the user's lead, e.g., topic switching.
            # For now, we just pass the message along.
            pass

        elif decision.response_strategy == ResponseStrategy.PROGRESS_TO_NEXT_CONCEPT:
           
            self.user_profile.knowledge_mastery[self.current_concept_id] = 1.0
            next_action_plan = self.analytical_planner.select_next_action(
                self.user_profile, self.knowledge_base, self.current_concept_id
            )
            if next_action_plan["action"] == "finish":
                self.state = TutorState.IDLE
                response_text = f"å¤ªæ£’äº†ï¼æˆ‘ä»¬å®Œæˆäº† **{self.knowledge_base.current_kb_name}** çš„å­¦ä¹ ã€‚"
            else:
                self.current_concept_id = next_action_plan["concept_id"]
                next_concept_info = self.knowledge_base.get_concept(self.current_concept_id)
                initial_question = next_concept_info.get('socratic_prompts', [""])[0]
                # å°†ä»£ç†çš„è¿‡æ¸¡æ–‡æœ¬ä¸æ–°æ¦‚å¿µçš„ç¬¬ä¸€ä¸ªé—®é¢˜ç»“åˆèµ·æ¥
                response_text = f"{decision.action.content}\n\nè®©æˆ‘ä»¬å¼€å§‹ä¸‹ä¸€ä¸ªæ¦‚å¿µï¼š**{self.current_concept_id}**ã€‚{initial_question}"

        # æ›´æ–°æŒæ¡ç¨‹åº¦ï¼ŒåŸºäºä»£ç†è‡ªå·±çš„åˆ†æ
        if decision.response_strategy in [ResponseStrategy.REVIEW_AND_CLARIFY]:
             self.user_profile.knowledge_mastery[self.current_concept_id] = max(0, self.user_profile.knowledge_mastery.get(self.current_concept_id, 0.1) - 0.2)
        elif decision.response_strategy in [ResponseStrategy.CONSOLIDATE_AND_VERIFY, ResponseStrategy.SOCRATIC_GUIDANCE]:
             self.user_profile.knowledge_mastery[self.current_concept_id] = min(1.0, self.user_profile.knowledge_mastery.get(self.current_concept_id, 0.0) + 0.2)

        # 6. å°†åˆ¶å¡æç¤ºä¸ä¸»è¦å“åº”ç»“åˆèµ·æ¥
        final_response = card_notification + response_text
        
        self._add_to_history("assistant", final_response)
        return final_response

    def _check_and_trigger_flashcard_creation(self, conversation_snippet: List[Dict[str, Any]]) -> int:
        """
        Checks a conversation snippet and creates flashcards if appropriate.
        Returns the number of cards created (0 if none).
        """
        if not conversation_snippet or len(conversation_snippet) < 2:
            return 0

        # Format history for the agents
        history_text = "\n".join([f"{msg['role'].capitalize()}: {msg['message'].content}" for msg in conversation_snippet])
        
        # 1. å†³å®šæ˜¯å¦å€¼å¾—åˆ¶ä½œå¤ä¹ å¡ç‰‡
        try:
            # æœ€åä¸€ä¸ªæ¶ˆæ¯æ˜¯ç”¨æˆ·ï¼Œå€’æ•°ç¬¬äºŒä¸ªæ¶ˆæ¯æ˜¯AI
            # æˆ‘ä»¬æƒ³è¦æ£€æŸ¥AIçš„è§£é‡Šæ˜¯å¦è¢«ç”¨æˆ·ç®€å•çš„ç¡®è®¤
            # æ˜¯å¦å€¼å¾—åˆ¶ä½œå¤ä¹ å¡ç‰‡
            if "user" not in conversation_snippet[-1]['role'].lower():
                 return 0 # The last message must be from the user

            decision_response = self.flashcard_decision_agent.step(history_text)
            # é‡è¦ï¼šé‡ç½®ä»£ç†çš„å†…å­˜ï¼Œç¡®ä¿æ¯æ¬¡æ£€æŸ¥éƒ½æ˜¯ç‹¬ç«‹çš„
            self.flashcard_decision_agent.reset() 
            if not decision_response or "YES" not in decision_response.msg.content.upper():
                return 0
        except Exception as e:
            print(f"[FlashcardCheck] Decision agent failed: {e}")
            return 0

        print("[FlashcardCheck] Decision: YES. Attempting to generate card.")

        # 2. ç”Ÿæˆå¤ä¹ å¡ç‰‡å†…å®¹
        try:
            generation_response = self.single_flashcard_agent.step(history_text)
            self.single_flashcard_agent.reset() 
            
            if not generation_response or not generation_response.msg.content:
                print("[FlashcardCheck] Generation agent returned no content.")
                return 0

            card_content_str = generation_response.msg.content
            
         
            # å¦‚æœå­˜åœ¨markdownä»£ç å—ï¼Œæå–JSON
            match = re.search(r'\{.*\}', card_content_str, re.DOTALL)
            if match:
                card_content_str = match.group(0)
       

            # è§£æå“åº”ä»¥è·å–å¡ç‰‡æ•°ç»„
            response_data = json.loads(card_content_str)
            
            # ä»å“åº”ä¸­è·å–å¡ç‰‡åˆ—è¡¨
            card_list = response_data.get("cards", [])
            
            if not isinstance(card_list, list) or not card_list:
                print(f"[FlashcardCheck] Generation agent returned no valid card list: {card_content_str}")
                return 0
            
            # è·Ÿè¸ªæˆåŠŸåˆ›å»ºäº†å¤šå°‘å¼ å¡ç‰‡
            cards_created_count = 0
            concept_id = self.current_concept_id or "from_conversation"
            
            # å¤„ç†åˆ—è¡¨ä¸­çš„æ¯å¼ å¡ç‰‡
            for card_item in card_list:
                question = card_item.get("question")
                answer = card_item.get("answer")
                
                if question and answer:
                    try:
                        new_card = self.review_manager.add_card(
                            concept_id=concept_id,
                            question=question,
                            answer=answer
                        )
                        if new_card:
                            cards_created_count += 1
                            print(f"[FlashcardCheck] Created card: Q: {question[:50]}...")
                    except Exception as e:
                        # å¦‚æœå•ä¸ªå¡ç‰‡å¤±è´¥ï¼Œè®°å½•ä½†ç»§ç»­å¤„ç†å…¶ä»–å¡ç‰‡
                        print(f"[FlashcardCheck] Failed to save a single card: {e}")
            
            if cards_created_count > 0:
                print(f"[FlashcardCheck] Successfully created and saved {cards_created_count} flashcard(s).")
                return cards_created_count
            else:
                print(f"[FlashcardCheck] No cards were ultimately created from the list.")
                return 0

        except json.JSONDecodeError as e:
            print(f"[FlashcardCheck] Failed to decode JSON from generation agent: {e}\nContent: '{card_content_str}'")
            return 0
        except Exception as e:
            print(f"[FlashcardCheck] Generation agent failed: {e}")
            return 0

    def _add_to_history(self, role: str, content: str):
        """Adds a message to the session's history."""
        if role.lower() == 'user':
            message = BaseMessage.make_user_message("user", content)
        else:
            message = BaseMessage.make_assistant_message("assistant", content)
        self.history.append({"role": role, "message": message}) 